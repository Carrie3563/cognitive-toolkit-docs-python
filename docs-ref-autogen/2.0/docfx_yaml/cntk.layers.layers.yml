api_name: []
items:
- _type: module
  children: []
  module: cntk.layers.layers
  name: cntk.layers.layers
  summary: 'Blocks in the network that are used layer-like, i.e. layered on top of
    each other

    e.g. a fully connected layer with non-linearity.

    '
  type: Namespace
  uid: cntk.layers.layers
- _type: class
  children:
  - cntk.layers.layers.Activation
  - cntk.layers.layers.AveragePooling
  - cntk.layers.layers.BatchNormalization
  - cntk.layers.layers.Convolution
  - cntk.layers.layers.Convolution1D
  - cntk.layers.layers.Convolution2D
  - cntk.layers.layers.Convolution3D
  - cntk.layers.layers.ConvolutionTranspose
  - cntk.layers.layers.ConvolutionTranspose1D
  - cntk.layers.layers.ConvolutionTranspose2D
  - cntk.layers.layers.ConvolutionTranspose3D
  - cntk.layers.layers.Dense
  - cntk.layers.layers.Dropout
  - cntk.layers.layers.Embedding
  - cntk.layers.layers.GlobalAveragePooling
  - cntk.layers.layers.GlobalMaxPooling
  - cntk.layers.layers.Label
  - cntk.layers.layers.LayerNormalization
  - cntk.layers.layers.MaxPooling
  - cntk.layers.layers.MaxUnpooling
  module: cntk.layers.layers
  name: cntk.layers.layers.Global
  summary: Proxy object to hold module level functions
  type: Class
  uid: cntk.layers.layers.Global
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Activation
  summary: "Layer factory function to create an activation layer.\nActivation functions\
    \ can be used directly in CNTK, so there is no difference between\n``y = relu(x)``\
    \ and ``y = Activation(relu)(x)``.\nThis layer is useful if one wants to configure\
    \ the activation function\nwith ``default_options``, or when its invocation should\
    \ be named.\n\n.. admonition:: Example\n\n   >>> model = Dense(500) >> Activation(C.relu)\
    \ >> Dense(10)\n   >>> # is the same as\n   >>> model = Dense(500) >> C.relu >>\
    \ Dense(10)\n   >>> # and also the same as\n   >>> model = Dense(500, activation=C.relu)\
    \ >> Dense(10)\n\n:param activation: function to apply at the end, e.g. `relu`\n\
    :type activation: :class:`~cntk.ops.functions.Function`, defaults to `identity`\n\
    :param name: the name of the function instance in the network\n:type name: str,\
    \ defaults to ''\n\n:returns: A function that accepts one argument and applies\
    \ the operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Activation
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.AveragePooling
  summary: "Layer factory function to create an average-pooling layer.\n\nLike ``Convolution()``,\
    \ ``AveragePooling()`` processes items arranged on an N-dimensional grid, such\
    \ as an image.\nTypically, each item is a vector.\nFor each item, average-pooling\
    \ computes the element-wise mean over a window (\"receptive field\") of items\
    \ surrounding the item's position on the grid.\n\nThe size (spatial extent) of\
    \ the receptive field is given by ``filter_shape``.\nE.g. for 2D pooling, ``filter_shape``\
    \ should be a tuple of two integers, such as `(5,5)`.\n\n.. admonition:: Example\n\
    \n   >>> f = AveragePooling((3,3), strides=2)  # reduce dimensionality by 2, pooling\
    \ over windows of 3x3\n   >>> h = C.input_variable((32,240,320))  # e.g. 32-dim\
    \ feature map\n   >>> hp = f(h)\n   >>> hp.shape  # spatial dimension has been\
    \ halved due to stride, and lost one due to 3x3 window without padding\n     \
    \  (32, 119, 159)\n   \n   >>> f = AveragePooling((2,2), strides=2)\n   >>> f.update_signature((1,4,4))\n\
    \   >>> im = np.array([[[3, 5, 2, 6], [4, 2, 8, 3], [1, 6, 4, 7], [7, 3, 5, 9]]])\
    \  # a 4x4 image (feature-map depth 1 for simplicity)\n   >>> im\n       array([[[3,\
    \ 5, 2, 6],\n               [4, 2, 8, 3],\n               [1, 6, 4, 7],\n    \
    \           [7, 3, 5, 9]]])\n   >>> f([[im]])  # due to strides=2, this computes\
    \ the averages of each 2x2 sub-block\n       array([[[[ 3.5 ,  4.75],\n      \
    \          [ 4.25,  6.25]]]], dtype=float32)\n\n:param filter_shape: shape (spatial\
    \ extent) of the receptive field, *not* including the input feature-map depth.\
    \ E.g. (3,3) for a 2D convolution.\n:type filter_shape: `int` or `tuple` of `ints`\n\
    :param strides: stride (increment when sliding over the input). Use a `tuple`\
    \ to specify a per-axis value.\n:type strides: `int` or `tuple` of `ints`, defaults\
    \ to 1\n:param pad: if `False`, then the pooling operation will be shifted over\
    \ the \"valid\"\n            area of input, that is, no value outside the area\
    \ is used. If ``pad=True`` on the other hand,\n            pooling will be applied\
    \ to all input positions, and positions outside the valid region will be excluded\
    \ from the averaging.\n            Use a `tuple` to specify a per-axis value.\n\
    :type pad: `bool` or `tuple` of `bools`, defaults to `False`\n:param name: the\
    \ name of the function instance in the network\n:type name: str, defaults to ''\n\
    \n:returns: A function that accepts one argument and applies the average-pooling\
    \ operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.AveragePooling
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.BatchNormalization
  summary: "Layer factory function to create a batch-normalization layer.\n\nBatch\
    \ normalization applies this formula to every input element (element-wise):\n\
    ``y = (x - batch_mean) / (batch_stddev + epsilon) * scale + bias``\nwhere ``batch_mean``\
    \ and ``batch_stddev`` are estimated on the minibatch and ``scale`` and ``bias``\
    \ are learned parameters.\n\nDuring operation, this layer also estimates an aggregate\
    \ running mean and standard deviation for use in inference.\n\nA ``BatchNormalization``\
    \ layer instance owns its learnable parameter tensors and exposes them as attributes\
    \ ``.scale`` and ``.bias``.\nThe aggregate estimates are exposed as attributes\
    \ ``aggregate_mean``, ``aggregate_variance``, and ``aggregate_count``.\n\n.. admonition::\
    \ Example\n\n   >>> # BatchNorm on an image with spatial pooling\n   >>> f = BatchNormalization(map_rank=1)\n\
    \   >>> f.update_signature((3,480,640))\n   >>> f.bias.shape, f.scale.shape  #\
    \ due to spatial pooling (map_rank=1), there are only 3 biases and scales, shared\
    \ across all pixel positions\n       ((3,), (3,))\n\n:param map_rank: passing\
    \ 1 means spatially-pooled batch-normalization, where normalization values will\
    \ be tied across all pixel positions; while ``None``\n                 will normalize\
    \ all elements of the input tensor independently\n:type map_rank: 1 or ``None``\n\
    :param init_scale: initial value for the ``scale`` parameter\n:type init_scale:\
    \ float, default 1\n:param normalization_time_constant: time constant for smoothing\
    \ the batch statistics in order to compute aggregate estimates for inference.\n\
    :type normalization_time_constant: int, default 5000\n:param epsilon: epsilon\
    \ added to the variance to avoid division by 0\n:type epsilon: float, default\
    \ 0.00001\n:param use_cntk_engine: if ``True`` then use CNTK's own engine instead\
    \ of NVidia's.\n:type use_cntk_engine: bool, default ``False``\n:param name: the\
    \ name of the function instance in the network\n:type name: str, optional\n\n\
    :returns: A function that accepts one argument and applies the operation to it\n\
    :rtype: cntk.ops.functions.Function\n\n.. todo:: Add paper reference.\n"
  type: Method
  uid: cntk.layers.layers.BatchNormalization
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Convolution
  summary: "Layer factory function to create a convolution layer.\n\nThis implements\
    \ a convolution operation over items arranged on an N-dimensional grid, such as\
    \ pixels in an image.\nTypically, each item is a vector (e.g. pixel: R,G,B), and\
    \ the result is, in turn, a vector.\nThe item-grid dimensions are referred to\
    \ as the *spatial* dimensions (e.g. dimensions of an image),\nwhile the vector\
    \ dimension of the individual items is often called *feature-map depth*.\n\nFor\
    \ each item, convolution gathers a window (\"receptive field\") of items surrounding\
    \ the item's position on the grid,\nand applies a little fully-connected network\
    \ to it (the same little network is applied to all item positions).\nThe size\
    \ (spatial extent) of the receptive field is given by ``filter_shape``.\nE.g.\
    \ to specify a 2D convolution, ``filter_shape`` should be a tuple of two integers,\
    \ such as `(5,5)`;\nan example for a 3D convolution (e.g. video or an MRI scan)\
    \ would be ``filter_shape=(3,3,3)``;\nwhile for a 1D convolution (e.g. audio or\
    \ text), ``filter_shape`` has one element, such as (3,) or just 3.\n\nThe dimension\
    \ of the input items (input feature-map depth) is not to be specified. It is known\
    \ from the input.\nThe dimension of the output items (output feature-map depth)\
    \ generated for each item position is given by ``num_filters``.\n\nIf the input\
    \ is a sequence, the sequence elements are by default treated independently.\n\
    To convolve along the sequence dimension as well, pass ``sequential=True``.\n\
    This is useful for variable-length inputs, such as video\nor natural-language\
    \ processing (word n-grams).\nNote, however, that convolution does not support\
    \ sparse inputs.\n\nBoth input and output items can be scalars intead of vectors.\
    \ For scalar-valued input items,\nsuch as pixels on a black-and-white image, or\
    \ samples of an audio clip, specify ``reduction_rank=0``.\nIf the output items\
    \ are scalar, pass ``num_filters=()`` or ``None``.\n\nA ``Convolution`` instance\
    \ owns its weight parameter tensors `W` and `b`, and exposes them as an attributes\
    \ ``.W`` and ``.b``.\nThe weights will have the shape ``(num_filters, input_feature_map_depth,\
    \ *filter_shape)``\n\n.. admonition:: Example\n\n   >>> # 2D convolution of 5x4\
    \ receptive field with output feature-map depth 128:\n   >>> f = Convolution((5,4),\
    \ 128, activation=C.relu)\n   >>> x = C.input_variable((3,480,640))  # 3-channel\
    \ color image\n   >>> h = f(x)\n   >>> h.shape\n       (128, 476, 637)\n   >>>\
    \ f.W.shape  # will have the form (num_filters, input_depth, *filter_shape)\n\
    \       (128, 3, 5, 4)\n   \n   >>> # 2D convolution over a one-channel black-and-white\
    \ image, padding, and stride 2 along width dimension\n   >>> f = Convolution((3,3),\
    \ 128, reduction_rank=0, pad=True, strides=(1,2), activation=C.relu)\n   >>> x\
    \ = C.input_variable((480,640))\n   >>> h = f(x)\n   >>> h.shape\n       (128,\
    \ 480, 320)\n   >>> f.W.shape\n       (128, 1, 3, 3)\n   \n   >>> # 3D convolution\
    \ along dynamic axis over a sequence of 2D color images\n   >>> from cntk.layers.typing\
    \ import Sequence, Tensor\n   >>> f = Convolution((2,5,4), 128, sequential=True,\
    \ activation=C.relu) # over 2 consecutive frames\n   >>> x = C.input_variable(**Sequence[Tensor[3,480,640]])\
    \  # a variable-length video of 640x480 RGB images\n   >>> h = f(x)\n   >>> h.shape\
    \   # this is the shape per video frame: 637x476 activation vectors of length\
    \ 128 each\n       (128, 476, 637)\n   >>> f.W.shape # (output featuer map depth,\
    \ input depth, and the three filter dimensions)\n       (128, 3, 2, 5, 4)\n\n\
    :param filter_shape: shape (spatial extent) of the receptive field, *not* including\
    \ the input feature-map depth. E.g. (3,3) for a 2D convolution.\n:type filter_shape:\
    \ `int` or `tuple` of `ints`\n:param num_filters: number of filters (output feature-map\
    \ depth), or ``()`` to denote scalar output items (output shape will have no depth\
    \ axis).\n:type num_filters: int, defaults to `None`\n:param sequential: if `True`,\
    \ also convolve along the dynamic axis. ``filter_shape[0]`` corresponds to dynamic\
    \ axis.\n:type sequential: bool, defaults to `False`\n:param activation: optional\
    \ function to apply at the end, e.g. `relu`\n:type activation: :class:`~cntk.ops.functions.Function`,\
    \ defaults to `identity`\n:param init: initial value of weights `W`\n:type init:\
    \ scalar or NumPy array or :mod:`cntk.initializer`, defaults to :func:`~cntk.initializer.glorot_uniform`\n\
    :param pad: if `False`, then the filter will be shifted over the \"valid\"\n \
    \           area of input, that is, no value outside the area is used. If ``pad=True``\
    \ on the other hand,\n            the filter will be applied to all input positions,\
    \ and positions outside the valid region will be considered containing zero.\n\
    \            Use a `tuple` to specify a per-axis value.\n:type pad: `bool` or\
    \ `tuple` of `bools`, defaults to `False`\n:param strides: stride of the convolution\
    \ (increment when sliding the filter over the input). Use a `tuple` to specify\
    \ a per-axis value.\n:type strides: `int` or `tuple` of `ints`, defaults to 1\n\
    :param sharing: When `True`, every position uses the same Convolution kernel.\
    \  When `False`, you can have a different Convolution kernel per position, but\
    \ `False` is not supported.\n:type sharing: bool, defaults to `True`\n:param bias:\
    \ the layer will have no bias if `False` is passed here\n:type bias: bool, optional,\
    \ defaults to `True`\n:param init_bias: initial value of weights `b`\n:type init_bias:\
    \ scalar or NumPy array or :mod:`cntk.initializer`, defaults to 0\n:param reduction_rank:\
    \ set to 0 if input items are scalars (input has no depth axis), e.g. an audio\
    \ signal or a black-and-white image\n                       that is stored with\
    \ tensor shape (H,W) instead of (1,H,W)\n:type reduction_rank: `int`, defaults\
    \ to 1\n:param transpose_weight: When this is `True` this is convolution, otherwise\
    \ this is correlation (which is common for most toolkits)\n:type transpose_weight:\
    \ bool, defaults to `False`\n:param max_temp_mem_size_in_samples: Limits the amount\
    \ of memory for intermediate convolution results.  A value of 0 means, memory\
    \ is automatically managed.\n:type max_temp_mem_size_in_samples: int, defaults\
    \ to 0\n:param name: the name of the function instance in the network\n:type name:\
    \ str, defaults to ''\n\n:returns: A function that accepts one argument and applies\
    \ the convolution operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Convolution
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Convolution1D
  summary: "Layer factory function to create a 1D convolution layer with optional\
    \ non-linearity.\nSame as `Convolution()` except that filter_shape is verified\
    \ to be 1-dimensional.\nSee `Convolution()` for extensive documentation.\n\n:param\
    \ filter_shape: shape (spatial extent) of the receptive field, *not* including\
    \ the input feature-map depth. E.g. (3,3) for a 2D convolution.\n:type filter_shape:\
    \ `int` or `tuple` of `ints`\n:param num_filters: number of filters (output feature-map\
    \ depth), or ``()`` to denote scalar output items (output shape will have no depth\
    \ axis).\n:type num_filters: int, defaults to `None`\n:param activation: optional\
    \ function to apply at the end, e.g. `relu`\n:type activation: :class:`~cntk.ops.functions.Function`,\
    \ defaults to `identity`\n:param init: initial value of weights `W`\n:type init:\
    \ scalar or NumPy array or :mod:`cntk.initializer`, defaults to :func:`~cntk.initializer.glorot_uniform`\n\
    :param pad: if `False`, then the filter will be shifted over the \"valid\"\n \
    \           area of input, that is, no value outside the area is used. If ``pad=True``\
    \ on the other hand,\n            the filter will be applied to all input positions,\
    \ and positions outside the valid region will be considered containing zero.\n\
    \            Use a `tuple` to specify a per-axis value.\n:type pad: `bool` or\
    \ `tuple` of `bools`, defaults to `False`\n:param strides: stride of the convolution\
    \ (increment when sliding the filter over the input). Use a `tuple` to specify\
    \ a per-axis value.\n:type strides: `int` or `tuple` of `ints`, defaults to 1\n\
    :param bias: the layer will have no bias if `False` is passed here\n:type bias:\
    \ bool, defaults to `True`\n:param init_bias: initial value of weights `b`\n:type\
    \ init_bias: scalar or NumPy array or :mod:`cntk.initializer`, defaults to 0\n\
    :param reduction_rank: set to 0 if input items are scalars (input has no depth\
    \ axis), e.g. an audio signal or a black-and-white image\n                   \
    \    that is stored with tensor shape (H,W) instead of (1,H,W)\n:type reduction_rank:\
    \ `int`, defaults to 1\n:param name: the name of the function instance in the\
    \ network\n:type name: str, defaults to ''\n\n:returns: A function that accepts\
    \ one argument and applies the convolution operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Convolution1D
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Convolution2D
  summary: "Layer factory function to create a 2D convolution layer with optional\
    \ non-linearity.\nSame as `Convolution()` except that filter_shape is verified\
    \ to be 2-dimensional.\nSee `Convolution()` for extensive documentation.\n\n:param\
    \ filter_shape: shape (spatial extent) of the receptive field, *not* including\
    \ the input feature-map depth. E.g. (3,3) for a 2D convolution.\n:type filter_shape:\
    \ `int` or `tuple` of `ints`\n:param num_filters: number of filters (output feature-map\
    \ depth), or ``()`` to denote scalar output items (output shape will have no depth\
    \ axis).\n:type num_filters: int, defaults to `None`\n:param activation: optional\
    \ function to apply at the end, e.g. `relu`\n:type activation: :class:`~cntk.ops.functions.Function`,\
    \ defaults to `identity`\n:param init: initial value of weights `W`\n:type init:\
    \ scalar or NumPy array or :mod:`cntk.initializer`, defaults to :func:`~cntk.initializer.glorot_uniform`\n\
    :param pad: if `False`, then the filter will be shifted over the \"valid\"\n \
    \           area of input, that is, no value outside the area is used. If ``pad=True``\
    \ on the other hand,\n            the filter will be applied to all input positions,\
    \ and positions outside the valid region will be considered containing zero.\n\
    \            Use a `tuple` to specify a per-axis value.\n:type pad: `bool` or\
    \ `tuple` of `bools`, defaults to `False`\n:param strides: stride of the convolution\
    \ (increment when sliding the filter over the input). Use a `tuple` to specify\
    \ a per-axis value.\n:type strides: `int` or `tuple` of `ints`, defaults to 1\n\
    :param bias: the layer will have no bias if `False` is passed here\n:type bias:\
    \ bool, defaults to `True`\n:param init_bias: initial value of weights `b`\n:type\
    \ init_bias: scalar or NumPy array or :mod:`cntk.initializer`, defaults to 0\n\
    :param reduction_rank: set to 0 if input items are scalars (input has no depth\
    \ axis), e.g. an audio signal or a black-and-white image\n                   \
    \    that is stored with tensor shape (H,W) instead of (1,H,W)\n:type reduction_rank:\
    \ `int`, defaults to 1\n:param name: the name of the function instance in the\
    \ network\n:type name: str, defaults to ''\n\n:returns: A function that accepts\
    \ one argument and applies the convolution operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Convolution2D
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Convolution3D
  summary: "Layer factory function to create a 3D convolution layer with optional\
    \ non-linearity.\nSame as `Convolution()` except that filter_shape is verified\
    \ to be 3-dimensional.\nSee `Convolution()` for extensive documentation.\n\n:param\
    \ filter_shape: shape (spatial extent) of the receptive field, *not* including\
    \ the input feature-map depth. E.g. (3,3) for a 2D convolution.\n:type filter_shape:\
    \ `int` or `tuple` of `ints`\n:param num_filters: number of filters (output feature-map\
    \ depth), or ``()`` to denote scalar output items (output shape will have no depth\
    \ axis).\n:type num_filters: int, defaults to `None`\n:param activation: optional\
    \ function to apply at the end, e.g. `relu`\n:type activation: :class:`~cntk.ops.functions.Function`,\
    \ defaults to `identity`\n:param init: initial value of weights `W`\n:type init:\
    \ scalar or NumPy array or :mod:`cntk.initializer`, defaults to :func:`~cntk.initializer.glorot_uniform`\n\
    :param pad: if `False`, then the filter will be shifted over the \"valid\"\n \
    \           area of input, that is, no value outside the area is used. If ``pad=True``\
    \ on the other hand,\n            the filter will be applied to all input positions,\
    \ and positions outside the valid region will be considered containing zero.\n\
    \            Use a `tuple` to specify a per-axis value.\n:type pad: `bool` or\
    \ `tuple` of `bools`, defaults to `False`\n:param strides: stride of the convolution\
    \ (increment when sliding the filter over the input). Use a `tuple` to specify\
    \ a per-axis value.\n:type strides: `int` or `tuple` of `ints`, defaults to 1\n\
    :param bias: the layer will have no bias if `False` is passed here\n:type bias:\
    \ bool, defaults to `True`\n:param init_bias: initial value of weights `b`\n:type\
    \ init_bias: scalar or NumPy array or :mod:`cntk.initializer`, defaults to 0\n\
    :param reduction_rank: set to 0 if input items are scalars (input has no depth\
    \ axis), e.g. an audio signal or a black-and-white image\n                   \
    \    that is stored with tensor shape (H,W) instead of (1,H,W)\n:type reduction_rank:\
    \ `int`, defaults to 1\n:param name: the name of the function instance in the\
    \ network\n:type name: str, defaults to ''\n\n:returns: A function that accepts\
    \ one argument and applies the convolution operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Convolution3D
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.ConvolutionTranspose
  summary: "Layer factory function to create a convolution transpose layer.\n\nThis\
    \ implements a convolution_transpose operation over items arranged on an N-dimensional\
    \ grid, such as pixels in an image.\nTypically, each item is a vector (e.g. pixel:\
    \ R,G,B), and the result is, in turn, a vector.\nThe item-grid dimensions are\
    \ referred to as the *spatial* dimensions (e.g. dimensions of an image),\nwhile\
    \ the vector dimensions of the individual items are often called *feature-map\
    \ depth*.\n\nConvolution transpose is also known as ``fractionally strided convolutional\
    \ layers``, or, ``deconvolution``.\nThis operation is used in image and language\
    \ processing applications. It supports arbitrary\ndimensions, strides, and padding.\n\
    \nThe forward and backward computation of convolution transpose is the inverse\
    \ of convolution. That is, during forward\npass the input layer's items are spread\
    \ into the output same as the backward spread of gradients in convolution. The\n\
    backward pass, on the other hand, performs a convolution same as the forward pass\
    \ of convolution.\n\nThe size (spatial extent) of the receptive field for convolution\
    \ transpose is given by ``filter_shape``.\nE.g. to specify a 2D convolution transpose,\
    \ ``filter_shape`` should be a tuple of two integers, such as `(5,5)`;\nan example\
    \ for a 3D convolution transpose (e.g. video or an MRI scan) would be ``filter_shape=(3,3,3)``;\n\
    while for a 1D convolution transpose (e.g. audio or text), ``filter_shape`` has\
    \ one element, such as (3,).\n\nThe dimension of the input items (feature-map\
    \ depth) is not specified, but known from the input.\nThe dimension of the output\
    \ items generated for each item position is given by ``num_filters``.\n\nA ``ConvolutionTranspose``\
    \ instance owns its weight parameter tensors `W` and `b`, and exposes them as\
    \ an attributes ``.W`` and ``.b``.\nThe weights will have the shape ``(input_feature_map_depth,\
    \ num_filters, *filter_shape)``.\n\n.. admonition:: Example\n\n   >>> # 2D convolution\
    \ transpose of 3x4 receptive field with output feature-map depth 128:\n   >>>\
    \ f = ConvolutionTranspose((3,4), 128, activation=C.relu)\n   >>> x = C.input_variable((3,480,640))\
    \  # 3-channel color image\n   >>> h = f(x)\n   >>> h.shape\n       (128, 482,\
    \ 643)\n   >>> f.W.shape  # will have the form (input_depth, num_filters, *filter_shape)\n\
    \       (3, 128, 3, 4)\n\n:param filter_shape: shape (spatial extent) of the receptive\
    \ field, *not* including the input feature-map depth. E.g. (3,3) for a 2D convolution.\n\
    :type filter_shape: `int` or tuple of `int`\\ s\n:param num_filters: number of\
    \ filters (output feature-map depth), or ``()`` to denote scalar output items\
    \ (output shape will have no depth axis).\n:type num_filters: int\n:param activation:\
    \ optional function to apply at the end, e.g. `relu`\n:type activation: :class:`~cntk.ops.functions.Function`,\
    \ optional\n:param init: initial value of weights `W`\n:type init: scalar or :mod:`cntk.initializer`,\
    \ default :func:`~cntk.initializer.glorot_uniform`\n:param pad: if `False`, then\
    \ the filter will be shifted over the \"valid\"\n            area of input, that\
    \ is, no value outside the area is used. If ``pad=True`` on the other hand,\n\
    \            the filter will be applied to all input positions, and positions\
    \ outside the valid region will be considered containing zero.\n            Use\
    \ a `tuple` to specify a per-axis value.\n:type pad: `bool` or tuple of `bool`\\\
    \ s, default `False`\n:param strides: stride of the convolution (increment when\
    \ sliding the filter over the input). Use a `tuple` to specify a per-axis value.\n\
    :type strides: `int` or tuple of `int`\\ s, default 1\n:param sharing: weight\
    \ sharing, must be True for now.\n:type sharing: `bool`, default `True`\n:param\
    \ bias: the layer will have no bias if `False` is passed here\n:type bias: `bool`,\
    \ optional, default `True`\n:param init_bias: initial value of weights `b`\n:type\
    \ init_bias: scalar or NumPy array or :mod:`cntk.initializer`\n:param output_shape:\
    \ output shape. When strides > 2, the output shape is non-deterministic. User\
    \ can specify the wanted output shape. Note the\n                     specified\
    \ shape must satisify the condition that if a convolution is perform from the\
    \ output with the same setting, the result must have same shape as the input.\n\
    :type output_shape: `int` or tuple of `int`\\ s\n:param reduction_rank: must be\
    \ 1 for now.\n                       that is stored with tensor shape (H,W) instead\
    \ of (1,H,W)\n:type reduction_rank: `int`, default 1\n:param max_temp_mem_size_in_samples:\
    \ set to a positive number to define the maximum workspace memory for convolution.\n\
    :type max_temp_mem_size_in_samples: `int`, default 0\n:param name: the name of\
    \ the Function instance in the network\n:type name: str, optional\n\n:returns:\
    \ :class:`~cntk.ops.functions.Function` that accepts one argument and applies\
    \ the convolution operation to it\n"
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.ConvolutionTranspose1D
  summary: 'Layer factory function to create a 1D convolution transpose layer with
    optional non-linearity.

    Same as `ConvolutionTranspose()` except that filter_shape is verified to be 1-dimensional.

    See `ConvolutionTranspose()` for extensive documentation.

    '
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose1D
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.ConvolutionTranspose2D
  summary: 'Layer factory function to create a 2D convolution transpose layer with
    optional non-linearity.

    Same as `ConvolutionTranspose()` except that filter_shape is verified to be 2-dimensional.

    See `ConvolutionTranspose()` for extensive documentation.

    '
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose2D
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.ConvolutionTranspose3D
  summary: 'Layer factory function to create a 3D convolution transpose layer with
    optional non-linearity.

    Same as `ConvolutionTranspose()` except that filter_shape is verified to be 3-dimensional.

    See `ConvolutionTranspose()` for extensive documentation.

    '
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose3D
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Dense
  summary: "Layer factory function to create an instance of a fully-connected linear\
    \ layer of the form\n`activation(input @ W + b)` with weights `W` and bias `b`,\
    \ and `activation` and `b` being optional.\n`shape` may describe a tensor as well.\n\
    \nA ``Dense`` layer instance owns its parameter tensors `W` and `b`, and exposes\
    \ them as attributes ``.W`` and ``.b``.\n\n.. admonition:: Example\n\n   >>> f\
    \ = Dense(5, activation=C.relu)\n   >>> x = C.input_variable(3)\n   >>> h = f(x)\n\
    \   >>> h.shape\n       (5,)\n   >>> f.W.shape\n       (3, 5)\n   >>> f.b.value\n\
    \       array([ 0.,  0.,  0.,  0.,  0.], dtype=float32)\n   \n   >>> # activation\
    \ through default options\n   >>> with C.default_options(activation=C.relu):\n\
    \   ...     f = Dense(500)\n\nThe ``Dense`` layer can be applied to inputs that\
    \ are tensors, not just vectors.\nThis is useful, e.g., at the top of a image-processing\
    \ cascade, where after many\nconvolutions with padding and strides it is difficult\
    \ to know the precise dimensions.\nFor this case, CNTK has an extended definition\
    \ of matrix product, in which\nthe input tensor will be treated as if it had been\
    \ automatically flattened.\nThe weight matrix will be a tensor that reflects the\
    \ \"flattened\" dimensions in its axes.\n\n.. admonition:: Example\n\n   >>> f\
    \ = Dense(5, activation=C.softmax) # a 5-class classifier\n   >>> x = C.input_variable((64,16,16))\
    \ # e.g. an image reduced by a convolution stack\n   >>> y = f(x)\n   >>> y.shape\n\
    \   (5,)\n   >>> f.W.shape  # \"row\" dimension of \"matrix\" consists of 3 axes\
    \ that match the input\n   (64, 16, 16, 5)\n\nThis behavior can be modified by\
    \ telling CNTK either the number of axes that should not be projected (``map_rank``)\n\
    or the rank of the input (``input_rank``). If neither is specified, all input\
    \ dimensions are\nprojected, as in the example above.\n\n.. admonition:: Example\n\
    \n   >>> f = Dense(5, activation=C.softmax, input_rank=2) # a 5-class classifier\n\
    \   >>> x = C.input_variable((10, 3, 3)) # e.g. 10 parallel 3x3 objects. Input\
    \ has input_rank=2 axes\n   >>> y = f(x)\n   >>> y.shape  # the 10 parallel objects\
    \ are classified separately, the \"10\" dimension is retained\n   (10, 5)\n  \
    \ >>> f.W.shape  # \"row\" dimension of \"matrix\" consists of (3,3) matching\
    \ the input axes to project\n   (3, 3, 5)\n   \n   >>> f = Dense(5, activation=C.softmax,\
    \ map_rank=2)\n   >>> x = C.input_variable((4, 6, 3, 3, 3)) # e.g. 24 parallel\
    \ 3x3x3 objects arranged in a 4x6 grid. The grid is to be retained\n   >>> y =\
    \ f(x)\n   >>> y.shape  # the 4x6 elements are classified separately, the grid\
    \ structure is retained\n   (4, 6, 5)\n   >>> f.W.shape  # \"row\" dimension of\
    \ \"matrix\" consists of (3,3) matching the input axes to project\n   (3, 3, 3,\
    \ 5)\n   >>> z = y([np.zeros(x.shape)])\n   >>> assert z.shape == (1, 4, 6, 5)\n\
    \n:param shape: vector or tensor dimension of the output of this layer\n:type\
    \ shape: `int` or `tuple` of `ints`\n:param activation: optional function to apply\
    \ at the end, e.g. `relu`\n:type activation: :class:`~cntk.ops.functions.Function`,\
    \ defaults to identity\n:param init: initial value of weights `W`\n:type init:\
    \ scalar or NumPy array or :mod:`cntk.initializer`, defaults to :func:`~cntk.initializer.glorot_uniform`\n\
    :param input_rank: number of inferred axes to add to W (`map_rank` must not be\
    \ given)\n:type input_rank: int, defaults to `None`\n:param map_rank: expand W\
    \ to leave exactly `map_rank` axes (`input_rank` must not be given)\n:type map_rank:\
    \ int, defaults to `None`\n:param bias: the layer will have no bias if `False`\
    \ is passed here\n:type bias: bool, optional, defaults to `True`\n:param init_bias:\
    \ initial value of weights `b`\n:type init_bias: scalar or NumPy array or :mod:`cntk.initializer`,\
    \ defualts to 0\n:param name: the name of the function instance in the network\n\
    :type name: str, defaults to ''\n\n:returns: A function that accepts one argument\
    \ and applies the operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Dense
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Dropout
  summary: "Layer factory function to create a drop-out layer.\n\nThe dropout rate\
    \ can be specified as the probability of *dropping* a value (``dropout_rate``).\n\
    E.g. ``Dropout(0.3)`` means \"drop 30% of the activation values.\"\nAlternatively,\
    \ it can also be specified as the probability of *keeping* a value (``keep_prob``).\n\
    \nThe dropout operation is only applied during training. During testing, this\
    \ is a no-op.\nTo make sure that this leads to correct results, the dropout operation\
    \ in training\nmultiplies the result by (1/(1-``dropout_rate``)).\n\n.. admonition::\
    \ Example\n\n   >>> f = Dropout(0.2)   # \"drop 20% of activations\"\n   >>> h\
    \ = C.input_variable(3)\n   >>> hd = f(h)\n   \n   >>> f = Dropout(keep_prob=0.8)\
    \   # \"keep 80%\"\n   >>> h = C.input_variable(3)\n   >>> hd = f(h)\n\n:param\
    \ dropout_rate: probability of dropping out an element, mutually exclusive with\
    \ ``keep_prob``\n:type dropout_rate: float\n:param keep_prob: probability of keeping\
    \ an element, mutually exclusive with ``dropout_rate``\n:type keep_prob: float\n\
    :param seed: random seed.\n:type seed: int\n:param name: the name of the function\
    \ instance in the network\n:type name: str, defaults to ''\n\n:returns: A function\
    \ that accepts one argument and applies the operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Dropout
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Embedding
  summary: "Layer factory function to create a embedding layer.\n\nAn embedding is\
    \ conceptually a lookup table. For every input token (e.g. a word or any category\
    \ label), the corresponding\nentry in in the lookup table is returned.\n\nIn CNTK,\
    \ discrete items such as words are represented as one-hot vectors.\nThe table\
    \ lookup is realized as a matrix product, with a matrix\nwhose rows are the embedding\
    \ vectors.\nNote that multiplying a matrix from the left with a one-hot vector\
    \ is the same as copying\nout the row for which the input vector is 1.\nCNTK has\
    \ special optimizations to make this operation as efficient as an actual table\
    \ lookup if the input is sparse.\n\nThe lookup table in this layer is learnable,\n\
    unless a user-specified one is supplied through the ``weights`` parameter.\nFor\
    \ example, to use an existing embedding table from a file in numpy format, use\
    \ this::\n\n  Embedding(weights=np.load('PATH.npy'))\n\nTo initialize a learnable\
    \ lookup table with a given numpy array that is to be used as\nthe initial value,\
    \ pass that array to the ``init`` parameter (not ``weights``).\n\nAn ``Embedding``\
    \ instance owns its weight parameter tensor `E`, and exposes it as an attribute\
    \ ``.E``.\n\n.. admonition:: Example\n\n   >>> # learnable embedding\n   >>> f\
    \ = Embedding(5)\n   >>> x = C.input_variable(3)\n   >>> e = f(x)\n   >>> e.shape\n\
    \       (5,)\n   >>> f.E.shape\n       (3, 5)\n   \n   >>> # user-supplied embedding\n\
    \   >>> f = Embedding(weights=[[.5, .3, .1, .4, .2], [.7, .6, .3, .2, .9]])\n\
    \   >>> f.E.value\n       array([[ 0.5,  0.3,  0.1,  0.4,  0.2],\n           \
    \   [ 0.7,  0.6,  0.3,  0.2,  0.9]], dtype=float32)\n   >>> x = C.input_variable(2,\
    \ is_sparse=True)\n   >>> e = f(x)\n   >>> e.shape\n       (5,)\n   >>> e(C.Value.one_hot([[1],\
    \ [0], [0], [1]], num_classes=2))\n   array([[ 0.7,  0.6,  0.3,  0.2,  0.9],\n\
    \          [ 0.5,  0.3,  0.1,  0.4,  0.2],\n          [ 0.5,  0.3,  0.1,  0.4,\
    \  0.2],\n          [ 0.7,  0.6,  0.3,  0.2,  0.9]], dtype=float32)\n\n:param\
    \ shape: vector or tensor dimension of the output of this layer\n:type shape:\
    \ `int` or `tuple` of `ints`\n:param init: (learnable embedding only) initial\
    \ value of weights `E`\n:type init: scalar or NumPy array or :mod:`cntk.initializer`,\
    \ defaults to :func:`~cntk.initializer.glorot_uniform`\n:param weights: (user-supplied\
    \ embedding only) the lookup table.\n                The matrix rows are the embedding\
    \ vectors, ``weights[i,:]`` being the embedding that corresponds to input category\
    \ `i`.\n:type weights: NumPy array, mutually exclusive with ``init``, defuats\
    \ to `None`\n:param name: the name of the function instance in the network\n:type\
    \ name: str, defaults to ''\n\n:returns: A function that accepts one argument\
    \ and applies the embedding operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Embedding
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.GlobalAveragePooling
  summary: "Layer factory function to create a global average-pooling layer.\n\nThe\
    \ global average-pooling operation computes the element-wise mean over all items\
    \ on an N-dimensional grid, such as an image.\n\nThis operation is the same as\
    \ applying ``reduce_mean()`` to all grid dimensions.\n\n.. admonition:: Example\n\
    \n   >>> f = GlobalAveragePooling()\n   >>> f.update_signature((1,4,4))\n   >>>\
    \ im = np.array([[[3, 5, 2, 6], [4, 2, 8, 3], [1, 6, 4, 7], [7, 3, 5, 9]]])  #\
    \ a 4x4 image (feature-map depth 1 for simplicity)\n   >>> im\n       array([[[3,\
    \ 5, 2, 6],\n               [4, 2, 8, 3],\n               [1, 6, 4, 7],\n    \
    \           [7, 3, 5, 9]]])\n   >>> f([[im]])\n       array([[[[ 4.6875]]]], dtype=float32)\n\
    \n:param name: the name of the function instance in the network\n:type name: str,\
    \ defaults to ''\n\n:returns: A function that accepts one argument and applies\
    \ the operation to it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.GlobalAveragePooling
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.GlobalMaxPooling
  summary: "Layer factory function to create a global max-pooling layer.\n\nThe global\
    \ max-pooling operation computes the element-wise maximum over all items on an\
    \ N-dimensional grid, such as an image.\n\nThis operation is the same as applying\
    \ ``reduce_max()`` to all grid dimensions.\n\n.. admonition:: Example\n\n   >>>\
    \ f = GlobalMaxPooling()\n   >>> f.update_signature((1,4,4))\n   >>> im = np.array([[[3,\
    \ 5, 2, 6], [4, 2, 8, 3], [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map\
    \ depth 1 for simplicity)\n   >>> im\n       array([[[3, 5, 2, 6],\n         \
    \      [4, 2, 8, 3],\n               [1, 6, 4, 7],\n               [7, 3, 5, 9]]])\n\
    \   >>> f([[im]])\n       array([[[[ 9.]]]], dtype=float32)\n\n:param name: the\
    \ name of the function instance in the network\n:type name: str, defaults to ''\n\
    \n:returns: A function that accepts one argument and applies the operation to\
    \ it\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.GlobalMaxPooling
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.Label
  summary: "Layer factory function to create a dummy layer with a given name.\nThis\
    \ can be used to access an intermediate value flowing through computation.\n\n\
    :param name: the name of the function instance in the network\n:type name: str\n\
    \n.. admonition:: Example\n\n   >>> model = Dense(500) >> Label('hidden') >> Dense(10)\n\
    \   >>> model.update_signature(10)\n   >>> intermediate_val = model.hidden\n \
    \  >>> intermediate_val.shape\n       (500,)\n\n:returns: A function that accepts\
    \ one argument and returns it with the desired name attached\n:rtype: cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.Label
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.LayerNormalization
  summary: "Layer factory function to create a function that implements layer normalization.\n\
    \nLayer normalization applies this formula to every input element (element-wise):\n\
    ``y = (x - mean(x)) / (stddev(x) + epsilon) * scale + bias``\nwhere ``scale``\
    \ and ``bias`` are learned scalar parameters.\n\n.. admonition:: Example\n\n \
    \  >>> f = LayerNormalization(initial_scale=2, initial_bias=1)\n   >>> f.update_signature(4)\n\
    \   >>> f([np.array([4,0,0,4])])  # result has mean 1 and standard deviation 2,\
    \ reflecting the initial values for scale and bias\n       array([[ 2.99999, -0.99999,\
    \ -0.99999,  2.99999]], dtype=float32)\n\n:param initial_scale: initial value\
    \ for the ``scale`` parameter\n:type initial_scale: float, default 1\n:param initial_bias:\
    \ initial value for the ``bias`` parameter\n:type initial_bias: float, default\
    \ 0\n:param epsilon: epsilon added to the standard deviation to avoid division\
    \ by 0\n:type epsilon: float, default 0.00001\n:param name: the name of the Function\
    \ instance in the network\n:type name: str, optional\n\n:returns: A function that\
    \ accepts one argument and applies the operation to it\n:rtype: cntk.ops.functions.Function\n\
    \n.. todo:: Add paper reference.\n"
  type: Method
  uid: cntk.layers.layers.LayerNormalization
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.MaxPooling
  summary: "Layer factory function to create a max-pooling layer.\n\nLike ``Convolution()``,\
    \ ``MaxPooling()`` processes items arranged on an N-dimensional grid, such as\
    \ an image.\nTypically, each item is a vector.\nFor each item, max-pooling computes\
    \ the element-wise maximum over a window (\"receptive field\") of items surrounding\
    \ the item's position on the grid.\n\nThe size (spatial extent) of the receptive\
    \ field is given by ``filter_shape``.\nE.g. for 2D pooling, ``filter_shape`` should\
    \ be a tuple of two integers, such as `(5,5)`.\n\n.. admonition:: Example\n\n\
    \   >>> f = MaxPooling((3,3), strides=2)  # reduce dimensionality by 2, pooling\
    \ over windows of 3x3\n   >>> h = C.input_variable((32,240,320))  # e.g. 32-dim\
    \ feature map\n   >>> hp = f(h)\n   >>> hp.shape  # spatial dimension has been\
    \ halved due to stride, and lost one due to 3x3 window without padding\n     \
    \  (32, 119, 159)\n   \n   >>> f = MaxPooling((2,2), strides=2)\n   >>> f.update_signature((1,4,4))\n\
    \   >>> im = np.array([[[3, 5, 2, 6], [4, 2, 8, 3], [1, 6, 4, 7], [7, 3, 5, 9]]])\
    \  # a 4x4 image (feature-map depth 1 for simplicity)\n   >>> im\n       array([[[3,\
    \ 5, 2, 6],\n               [4, 2, 8, 3],\n               [1, 6, 4, 7],\n    \
    \           [7, 3, 5, 9]]])\n   >>> f([[im]])  # due to strides=2, this picks\
    \ the max out of each 2x2 sub-block\n       array([[[[ 5.,  8.],\n           \
    \     [ 7.,  9.]]]], dtype=float32)\n\n:param filter_shape: shape (spatial extent)\
    \ of the receptive field, *not* including the input feature-map depth. E.g. (3,3)\
    \ for a 2D convolution.\n:type filter_shape: `int` or `tuple` of `ints`\n:param\
    \ strides: stride (increment when sliding over the input). Use a `tuple` to specify\
    \ a per-axis value.\n:type strides: `int` or `tuple` of `ints`, defaults to 1\n\
    :param pad: if `False`, then the pooling operation will be shifted over the \"\
    valid\"\n            area of input, that is, no value outside the area is used.\
    \ If ``pad=True`` on the other hand,\n            pooling will be applied to all\
    \ input positions, and positions outside the valid region will be considered containing\
    \ zero.\n            Use a `tuple` to specify a per-axis value.\n:type pad: `bool`\
    \ or `tuple` of `bools`, defaults to `False`\n:param name: the name of the function\
    \ instance in the network\n:type name: str, defaults to ''\n\n:returns: A function\
    \ that accepts one argument and applies the max-pooling operation to it\n:rtype:\
    \ cntk.ops.functions.Function\n"
  type: Method
  uid: cntk.layers.layers.MaxPooling
- _type: function
  module: cntk.layers.layers
  name: cntk.layers.layers.MaxUnpooling
  summary: ''
  type: Method
  uid: cntk.layers.layers.MaxUnpooling
