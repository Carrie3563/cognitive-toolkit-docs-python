api_name: []
items:
- _type: module
  children:
  - cntk.ops.functions.CloneMethod
  - cntk.ops.functions.Function
  - cntk.ops.functions.UserFunction
  module: cntk.ops.functions
  name: cntk.ops.functions
  summary: ''
  type: Namespace
  uid: cntk.ops.functions
- _type: class
  children:
  - cntk.ops.functions.BlockFunction
  - cntk.ops.functions.load_model
  - cntk.ops.functions.native_user_function
  - cntk.ops.functions.register_native_user_function
  module: cntk.ops.functions
  name: cntk.ops.functions.Global
  summary: Proxy object to hold module level functions
  type: Class
  uid: cntk.ops.functions.Global
- _type: function
  module: cntk.ops.functions
  name: cntk.ops.functions.BlockFunction
  summary: 'Decorator for defining a @Function as a BlockFunction. Same as @Function,
    but wrap the content into an :func:`~cntk.ops.as_block`.

    '
  type: Method
  uid: cntk.ops.functions.BlockFunction
- _type: class
  children:
  - cntk.ops.functions.CloneMethod.clone
  - cntk.ops.functions.CloneMethod.freeze
  - cntk.ops.functions.CloneMethod.share
  module: cntk.ops.functions
  name: cntk.ops.functions.CloneMethod
  summary: 'Describes different ways how :func:`~cntk.ops.functions.Function.clone`

    works.

    '
  type: Class
  uid: cntk.ops.functions.CloneMethod
- _type: attribute
  class: cntk.ops.functions.CloneMethod
  module: cntk.ops.functions
  name: cntk.ops.functions.CloneMethod.clone
  summary: 'New learnable parameters are created and initialized with the current
    values of the

    corresponding parameters of the Function being cloned'
  type: Property
  uid: cntk.ops.functions.CloneMethod.clone
- _type: attribute
  class: cntk.ops.functions.CloneMethod
  module: cntk.ops.functions
  name: cntk.ops.functions.CloneMethod.freeze
  summary: 'Parameters are cloned and made immutable; i.e. Constants in the new clone

    (e.g. for use as a fixed feature extractor)'
  type: Property
  uid: cntk.ops.functions.CloneMethod.freeze
- _type: attribute
  class: cntk.ops.functions.CloneMethod
  module: cntk.ops.functions
  name: cntk.ops.functions.CloneMethod.share
  summary: Parameters are shared between the Function being cloned and the new clone
  type: Property
  uid: cntk.ops.functions.CloneMethod.share
- _type: class
  children:
  - cntk.ops.functions.Function.argument_map
  - cntk.ops.functions.Function.arguments
  - cntk.ops.functions.Function.attributes
  - cntk.ops.functions.Function.backward
  - cntk.ops.functions.Function.block_arguments_mapping
  - cntk.ops.functions.Function.block_root
  - cntk.ops.functions.Function.clone
  - cntk.ops.functions.Function.constants
  - cntk.ops.functions.Function.declare_args
  - cntk.ops.functions.Function.eval
  - cntk.ops.functions.Function.find_all_with_name
  - cntk.ops.functions.Function.find_by_name
  - cntk.ops.functions.Function.forward
  - cntk.ops.functions.Function.grad
  - cntk.ops.functions.Function.inputs
  - cntk.ops.functions.Function.is_block
  - cntk.ops.functions.Function.is_composite
  - cntk.ops.functions.Function.is_primitive
  - cntk.ops.functions.Function.load
  - cntk.ops.functions.Function.name
  - cntk.ops.functions.Function.op_name
  - cntk.ops.functions.Function.output
  - cntk.ops.functions.Function.outputs
  - cntk.ops.functions.Function.parameters
  - cntk.ops.functions.Function.placeholders
  - cntk.ops.functions.Function.register_udf_deserialize_callback
  - cntk.ops.functions.Function.replace_placeholder
  - cntk.ops.functions.Function.replace_placeholders
  - cntk.ops.functions.Function.restore
  - cntk.ops.functions.Function.root_function
  - cntk.ops.functions.Function.save
  - cntk.ops.functions.Function.set_attribute
  - cntk.ops.functions.Function.signature
  - cntk.ops.functions.Function.test
  - cntk.ops.functions.Function.train
  - cntk.ops.functions.Function.type
  - cntk.ops.functions.Function.uid
  - cntk.ops.functions.Function.update_signature
  - cntk.ops.functions.Function.with_signature
  module: cntk.ops.functions
  name: cntk.ops.functions.Function
  summary: "Base class of all primitive tensor operators.\n\nIf it has only one output,\
    \ one can invoke Variable methods on it, which it\nwill relay to its only output.\n\
    \n`Function` objects can also be constructed directly from a Python lambda,\n\
    by means of the `@Function` decorator.\nThe `Function`'s input signature is defined\
    \ by the lambda.\n\n.. admonition:: Example\n\n   >>> @Function\n   ... def f(x):\n\
    \   ...     return x * x\n   >>> print(f)    # inspect the Function's type\n \
    \  ElementTimes(x: Sequence[tensor]) -> Sequence[tensor]\n\nThe above form creates\
    \ a CNTK Function whose arguments are placeholder variables.\nSuch a function\
    \ can only be combined with other symbolic functions.\n\nTo train a Function or\
    \ pass data to it, you need to declare the types\nof the arguments. In this case,\
    \ the @Function decorator creates a CNTK Function\nwhose arguments are input variables.\n\
    \nIf you use Python 3, Functions with types are declared using Python annotation\
    \ syntax, e.g.::\n\n  @Function\n  def f(x:Tensor[13]):\n      return x * x\n\n\
    If you are working with Python 2.7, use CNTK's :class:`@Signature <cntk.layers.typing.Signature>`\
    \ decorator instead::\n\n  >>> from cntk.layers.typing import *\n  >>> @Function\n\
    \  ... @Signature(Tensor[13])\n  ... def f(x):\n  ...     return x * x\n  >>>\
    \ print(f)\n  ElementTimes(x: Tensor[13]) -> Tensor[13]\n\n``make_block=True``\
    \ is an internal parameter used to implement :func:`@BlockFunction <cntk.ops.functions.BlockFunction>`.\n\
    If `BlockFunction()` passes `True`, then the result will be wrapped\nin :func:`~cntk.ops.as_block()`,\
    \ using the supplied ``op_name`` and ``name`` parameters, which are otherwise\
    \ ignored.\n"
  type: Class
  uid: cntk.ops.functions.Function
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.argument_map
  summary: 'Determines the {placeholder: variable} map for use with various call operations

    Returns a dictionary from this function''s placeholders to whatever arguments
    are passed.

    Accepted are both positional and keyword arguments.

    This mimics Python''s argument interpretation, except that keyword arguments are
    not optional

    (there is no concept of default value).

    This does not require the arguments to be Variables or Functions. It is also called
    by train_minibatch().

    '
  type: Method
  uid: cntk.ops.functions.Function.argument_map
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.arguments
  summary: List of all input variables of the Function that are not of type Parameter
    or Constant
  type: Property
  uid: cntk.ops.functions.Function.arguments
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.attributes
  summary: List of the attributes of the function
  type: Property
  uid: cntk.ops.functions.Function.attributes
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.backward
  summary: "Backpropagates supplied ``root_gradients`` for one or more of the output\n\
    variables of the Function, to calculate gradients with respect to\n``variables``.\
    \ Formally, multiplies the values of ``root_gradients`` by\nthe Jacobian of the\
    \ Function and returns the subset of the output that\ncorresponds to ``variables``.\n\
    \n.. admonition:: Example\n\n   >>> # compute the value and the derivative of\
    \ the sigmoid at 0\n   >>> v = C.input_variable(shape=(1,), needs_gradient=True)\n\
    \   >>> f = C.sigmoid(v)\n   >>> df, fv = f.forward({v:[[0]]}, [f.output], set([f.output]))\n\
    \   >>> value = list(fv.values())[0]\n   >>> grad = f.backward(df, {f.output:\
    \ np.ones_like(value)}, set([v]))\n   >>> value\n   array([[ 0.5]], dtype=float32)\n\
    \   >>> list(grad.values())[0]\n   array([[ 0.25]], dtype=float32)\n\n:param state:\
    \ state obtained from a previous call to the\n              func:`cntk.ops.Function.forward`\
    \ method on this Function for the\n              computation that this gradient\
    \ backpropagation corresponds to.\n:type state: BackPropState\n:param root_gradients:\
    \ the gradients that will be backpropagated\n:type root_gradients: dict\n:param\
    \ variables: a list of input variables with respect to which\n               \
    \   the gradients have to be computed.\n:type variables: set\n:param as_numpy:\
    \ whether to return the gradients as a NumPy array. Default True.\n          \
    \       Specifying this as False returns a CNTK Value which avoids a\n       \
    \          costly conversion but returns a somewhat opaque object. Also, the Value\
    \ objects\n                 are temporary and only guaranteed to be valid until\
    \ the next forward/eval/backward/grad call.\n                 You must explicitly\
    \ clone the temporay Value objects if they need to be accessed later.\n:type as_numpy:\
    \ bool\n\n.. note::\n\n   See :meth:`~cntk.ops.functions.Function.forward` for\
    \ more examples\n   on passing input data.\n\n:returns: mapping of ``variables``\
    \ to NumPy arrays\n:rtype: dict\n"
  type: Method
  uid: cntk.ops.functions.Function.backward
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.block_arguments_mapping
  summary: 'Returns the mapping from the arguments of the composite underlying this
    block function

    to the Variables that they are bound to in the outer graph of Functions that this

    block Function is part of.'
  type: Property
  uid: cntk.ops.functions.Function.block_arguments_mapping
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.block_root
  summary: 'Returns the root of the Function graph underlying this block Function.

    Throws an exception if this is not a block Function.'
  type: Property
  uid: cntk.ops.functions.Function.block_root
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.clone
  summary: "Clones the function. The parameters of the Function are either cloned,\n\
    shared or frozen as specified by the method argument and any variable\nsubstitutions\
    \ requested are applied in the cloned Function instance.\n\n:param method: one\
    \ of\n\n               * 'clone': the returned function gets its own copy of parameters\
    \ (default)\n               * 'share': the returned function shares its parameters\
    \ with this function\n               * 'freeze': parameters are cloned and made\
    \ immutable (constant).\n:type method: :class:`CloneMethod`\n:param substitutions:\
    \ a dictionary mapping variables in this\n                      function to variables\
    \ in the cloned function\n:type substitutions: dict\n\n:returns: the cloned Function\n\
    :rtype: :class:`~cntk.ops.functions.Function`\n"
  type: Method
  uid: cntk.ops.functions.Function.clone
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.constants
  summary: List of all `Constant` variables of this :class:`~cntk.ops.functions.Function`
  type: Property
  uid: cntk.ops.functions.Function.constants
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.declare_args
  summary: 'Back-compat wrapper for update_signature() (beta12 and before).

    '
  type: Method
  uid: cntk.ops.functions.Function.declare_args
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.eval
  summary: "Evaluate the Function's outputs using the specified ``arguments`` as input.\n\
    \n:param arguments: maps variables to their input data. The interpretation depends\
    \ on\n                  the input type:\n\n                   * dict: keys are\
    \ input variable or names, and values are the input data.\n                  \
    \   See :meth:`~cntk.ops.functions.Function.forward` for details on passing\n\
    \                     input data.\n                   * any other type: if node\
    \ has a unique input, arguments is\n                     mapped to this input.\n\
    \n                  For nodes with more than one input, only dict is allowed.\n\
    \n                  In both cases, every sample in the data will be interpreted\n\
    \                  as a new sequence.\n\n                  Sequences can be marked\
    \ as continuations of the same sequence in\n                  the previous minibatch\
    \ (that is the sequence in the same slot).\n                  There are two possibilities\
    \ for this:\n\n                   * specifying arguments as a `tuple` where the\
    \ first element is\n                     used as arguments and the second one\
    \ will be used as a list\n                     of bools, denoting whether a sequence\
    \ is a new one (`True`) or a\n                     continuation of the sequence\
    \ in the same slot of the previous\n                     minibatch (`False`).\
    \ This will be applied to all batches.\n                   * specifying arguments\
    \ as a dictionary of variables to tuples\n                     where the first\
    \ element is used as arguments and the second\n                     one will be\
    \ used as a list of bools, denoting whether a sequence\n                     is\
    \ a new one (`True`) or a continuation of the sequence in the\n              \
    \       same slot of the previous minibatch (`False`). This will be\n        \
    \             applied to all batches.\n\n                  Data should be either\
    \ NumPy arrays or a\n                  :class:`~cntk.io.MinibatchData` instance.\n\
    :param outputs: outputs to fetch values for. If not\n                set, all\
    \ outputs of the function will be fetched.\n:type outputs: iterable, optional\n\
    :param device: the device descriptor that\n               contains the type and\
    \ id of the device on which the computation is\n               to be performed.\n\
    :type device: :class:`~cntk.device.DeviceDescriptor`\n:param as_numpy: whether\
    \ to return the result as a NumPy array. Default True.\n                 Specifying\
    \ this as False returns a CNTK Value which avoids a\n                 costly conversion\
    \ but returns a somewhat opaque object. Also, the Value objects\n            \
    \     are temporary and only guaranteed to be valid until the next forward/eval/backward/grad\
    \ call.\n                 You must explicitly clone the temporay Value objects\
    \ if they need to be accessed later.\n:type as_numpy: bool\n\n.. note::\n\n  \
    \ See :meth:`~cntk.ops.functions.Function.forward` for examples on\n   passing\
    \ input data.\n\n:returns: Dict with keys of ouput variable names and values of\n\
    \          output variable. A single NumPy array if there is only one output value.\n\
    :rtype: dict or NumPy Array\n"
  type: Method
  uid: cntk.ops.functions.Function.eval
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.find_all_with_name
  summary: "Returns a list of primitive function with ``name`` in the graph\nstarting\
    \ from this node. Throws an exception if ``name`` occurs\nmultiple times. If you\
    \ expect only one function to be returned, use\n:func:`find_by_name`.\n\n.. admonition::\
    \ Example\n\n   >>> a = C.input_variable(shape=1, name='i')\n   >>> b = C.input_variable(shape=1,\
    \ name='i')\n   >>> c = C.plus(a, b, name='c')\n   >>> len(c.find_all_with_name('i'))\n\
    \   2\n   >>> c.find_all_with_name('z')\n   []\n\n:param name: names to look for\n\
    :type name: str\n:param depth: how deep into the block hierarchy the DFS\n   \
    \           algorithm should go into. Set to -1 for infinite depth.\n:type depth:\
    \ int, default 0\n\n:returns: list of :class:`Function` objects matching ``name``\n\
    \n.. seealso:: :func:`find_by_name`\n"
  type: Method
  uid: cntk.ops.functions.Function.find_all_with_name
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.find_by_name
  summary: "Returns a primitive function with ``name`` in the graph starting from\n\
    this node. Throws an exception if ``name`` occurs multiple times. If\nyou expect\
    \ multiple functions to be returned, use\n:func:`find_all_with_name`.\n\n.. admonition::\
    \ Example\n\n   >>> a = C.input_variable(shape=1, name='a')\n   >>> b = C.input_variable(shape=1,\
    \ name='b')\n   >>> c = C.plus(a, b, name='c')\n   >>> print(c.find_by_name('b').name)\n\
    \   b\n   >>> c.find_by_name('z') is None\n   True\n   \n   If you need a full\
    \ function out of it that can be evaluated, you\n   need to upcast it (currently\
    \ done via combine):\n   \n   >>> d = c * 5\n   >>> C.combine([d.find_by_name('c')]).eval({a:[[1]],\
    \ b:[[2]]})\n   array([[ 3.]], dtype=float32)\n\n:param name: names to look for\n\
    :type name: str\n:param depth: how deep into the block hierarchy the DFS\n   \
    \           algorithm should go into. Set to -1 for infinite depth.\n:type depth:\
    \ int, default 0\n\n:returns: :class:`Function` object matching ``name``\n\n..\
    \ seealso:: :func:`find_all_with_name`\n"
  type: Method
  uid: cntk.ops.functions.Function.find_by_name
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.forward
  summary: "Computes the values of speficied variables in ``outputs``, using values\n\
    provided in ``arguments`` that correspond to each input `Variable` of\nthe function\
    \ (i.e. those that have ``is_input = True``).\n\n.. admonition:: Example\n\n \
    \  >>> # Example of passing dense data\n   >>> v = C.input_variable(shape=(3,))\n\
    \   >>> f = C.reciprocal(v)\n   >>> _, fv = f.forward({v:[[1, 2, 4]]})\n   >>>\
    \ list(fv.values())[0]\n   array([[ 1.  ,  0.5 ,  0.25]], dtype=float32)\n\n..\
    \ admonition:: Example\n\n   >>> # Passing sparse values as one-hot with a vocabulary\
    \ size of 5\n   >>> vocab_size = 5\n   >>> v = C.sequence.input_variable(shape=(vocab_size,),\
    \ is_sparse=True)\n   >>> f = C.times(v, np.eye(vocab_size))\n   >>> # Passing\
    \ a batch of two sequences:\n   >>> # 1st sequence: word 1\n   >>> # 2nd sequence:\
    \ words 2 and 4\n   >>> batch = [[1],[2,4]]\n   >>> sparse_batch = C.Value.one_hot(batch,\
    \ vocab_size)\n   >>> _, fv = f.forward({v:sparse_batch})\n   >>> list(fv.values())[0]\n\
    \   [array([[ 0.,  1.,  0.,  0.,  0.]], dtype=float32),\n    array([[ 0.,  0.,\
    \  1.,  0.,  0.], [ 0.,  0.,  0.,  0.,  1.]], dtype=float32)]\n\n.. admonition::\
    \ Example\n\n   >>> # Doing the same, but with a CSR matrix from scipy.sparse\n\
    \   >>> vocab_size = 5\n   >>> from scipy.sparse import csr_matrix\n   >>> v =\
    \ C.sequence.input_variable(shape=(vocab_size,), is_sparse=True)\n   >>> f = C.times(v,\
    \ np.eye(vocab_size))\n   >>> # Note that csr_matrix automatically uses a sparse\
    \ representation underneath.\n   >>> sparse_batch = [csr_matrix([[0,1,0,0,0]]),\
    \ csr_matrix([[0,0,1,0,0], [0,0,0,0,1]])]\n   >>> _, fv = f.forward({v:sparse_batch})\n\
    \   >>> list(fv.values())[0]\n   [array([[ 0.,  1.,  0.,  0.,  0.]], dtype=float32),\n\
    \    array([[ 0.,  0.,  1.,  0.,  0.], [ 0.,  0.,  0.,  0.,  1.]], dtype=float32)]\n\
    \   <BLANKLINE>\n   >>> # Much more efficient, however, is to incrementally create\
    \ CSR arrays.\n   >>> # See https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n\
    \   >>> # for more information.\n   >>> def seq_to_csr_matrix(seq, vocab_size):\n\
    \   ...     indptr = [0]\n   ...     indices = []\n   ...     data = []\n   ...\
    \     for term_idx in seq:\n   ...         indices.append(term_idx)\n   ...  \
    \       data.append(1)\n   ...         indptr.append(len(indices))\n   ...   \
    \  return csr_matrix((data, indices, indptr), shape=(len(seq), vocab_size))\n\
    \   >>> sparse_batch = [seq_to_csr_matrix(seq, vocab_size) for seq in batch]\n\
    \   >>> _, fv = f.forward({v:sparse_batch})\n   >>> list(fv.values())[0]\n   [array([[\
    \ 0.,  1.,  0.,  0.,  0.]], dtype=float32),\n    array([[ 0.,  0.,  1.,  0., \
    \ 0.], [ 0.,  0.,  0.,  0.,  1.]], dtype=float32)]\n\n:param arguments: maps variables\
    \ to their input data. The interpretation depends on\n                  the input\
    \ type:\n\n                   * dict: keys are input variable or names, and values\
    \ are the\n                     input data. To specify a minibatch, provide a\
    \ list of arrays.\n                     The shape of each array must be compatible\
    \ with the shape of\n                     the dictionary key. If the array denotes\
    \ a sequence then the\n                     elements of the sequence are grouped\
    \ along axis 0.\n                   * any other type: if node has a unique input,\
    \ arguments is\n                     mapped to this input.\n\n               \
    \   For nodes with more than one input, only dict is allowed.\n\n            \
    \      In both cases, every sample in the data will be interpreted\n         \
    \         as a new sequence.\n\n                  Sequences can be marked as continuations\
    \ of the same sequence in\n                  the previous minibatch (that is the\
    \ sequence in the same slot).\n                  There are two possibilities for\
    \ this:\n\n                   * specifying arguments as a `tuple` where the first\
    \ element is\n                     used as arguments and the second one will be\
    \ used as a list\n                     of bools, denoting whether a sequence is\
    \ a new one (`True`) or a\n                     continuation of the sequence in\
    \ the same slot of the previous\n                     minibatch (`False`). This\
    \ will be applied to all batches.\n                   * specifying arguments as\
    \ a dictionary of variables to tuples\n                     where the first element\
    \ is used as arguments and the second\n                     one will be used as\
    \ a list of bools, denoting whether a sequence\n                     is a new\
    \ one (`True`) or a continuation of the sequence in the\n                    \
    \ same slot of the previous minibatch (`False`). This will be\n              \
    \       applied to all batches.\n\n                  Data should be either NumPy\
    \ arrays or a\n                  :class:`~cntk.io.MinibatchData` instance.\n:param\
    \ outputs: outputs to fetch values for. If not\n                set, all outputs\
    \ of the function will be fetched.\n:type outputs: iterable, optional\n:param\
    \ keep_for_backward: the subset of the\n                          Function's output\
    \ variables for which gradients shall be calculated\n                        \
    \  in a subsequent backward call. If `None`, the returned state will\n       \
    \                   be `None` and a subsequent call to :func:`backward` will not\
    \ be\n                          possible.\n:type keep_for_backward: set, default\
    \ `None`\n:param device: the device\n               descriptor that contains the\
    \ type and id of the device on which the\n               computation is. If `None`,\
    \ the default device is used.\n:type device: :class:`~cntk.device.DeviceDescriptor`,\
    \ default `None`\n:param as_numpy: whether to return the result as a NumPy array.\
    \ Default True.\n                 Specifying this as False returns a CNTK Value\
    \ which avoids a\n                 costly conversion but returns a somewhat opaque\
    \ object. Also, the Value objects\n                 are temporary and only guaranteed\
    \ to be valid until the next forward/eval/backward/grad call.\n              \
    \   You must explicitly clone the temporay Value objects if they need to be accessed\
    \ later.\n:type as_numpy: bool\n\n:returns: A tuple (BackPropState, map of outputs\
    \ to NumPy arrays). The\n          BackPropState is a handle taken by :func:`backward`.\n"
  type: Method
  uid: cntk.ops.functions.Function.forward
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.grad
  summary: "Computes the gradient of this Function at location ``at`` with respect\
    \ to ``wrt``.\nThe Function must have a single output.\n\n.. admonition:: Example\n\
    \n   >>> x = C.input_variable(shape=(1,), needs_gradient=True)\n   >>> y = C.sqrt(x)\n\
    \   >>> a = np.asarray([1,4,16],dtype=np.float32).reshape(3,1)\n   >>> y.grad({x:a})\n\
    \   array([[ 0.5  ],\n   <BLANKLINE>\n          [ 0.25 ],\n   <BLANKLINE>\n  \
    \        [ 0.125]], dtype=float32)\n\n:param at: mapping of the Function's arguments\
    \ to values\n:type at: dict\n:param wrt: list of Variables with respect to which\
    \ the\n            gradient will be computed. If omitted, the gradients with\n\
    \            respect to all arguments of this Function that need gradient will\
    \ be computed.\n:type wrt: list, default `None`\n:param outputs: outputs (including\
    \ intermediate outputs in the graph)\n                to fetch values for. If\
    \ not specified, values for none of the outputs are fetched.\n:type outputs: iterable,\
    \ optional\n:param device: the device\n               descriptor that contains\
    \ the type and id of the device on which the\n               computation is performed.\
    \ If `None`, the default device is used.\n:type device: :class:`~cntk.device.DeviceDescriptor`,\
    \ default `None`\n:param as_numpy: whether to return the gradients as a NumPy\
    \ array. Default True.\n                 Specifying this as False returns a CNTK\
    \ Value which avoids a\n                 costly conversion but returns a somewhat\
    \ opaque object. Also, the Value objects\n                 are temporary and only\
    \ guaranteed to be valid until the next forward/eval/backward/grad call.\n   \
    \              You must explicitly clone the temporay Value objects if they need\
    \ to be accessed later.\n:type as_numpy: bool, default `True`\n:param grad_root:\
    \ specify the root of gradients calculation.\n                  If not specified,\
    \ the output of this function will be used as gradient root.\n:type grad_root:\
    \ :class:`~cntk.variables.Variable`, optional\n\n:returns: Dict with keys of ``wrt``\
    \ variables and gradient values of\n          ``wrt`` variables. A single NumPy\
    \ array if there is only one gradient value.\n          If ``outputs`` were specified\
    \ (to fetch values for), this method returns a tuple where the 2nd element\n \
    \         of the tuple is the ``outputs`` values; a dict with keys of specified\
    \ ``outputs`` variables and\n          values of computed ``outputs``, or a single\
    \ NumPy array if there is only one output value.\n          Each element has the\
    \ same shape as the ``wrt`` or ``outputs`` variables including dynamic axes\n\
    \          (such as the batch axis).\n:rtype: dict or NumPy Array or a tuple of\
    \ these\n"
  type: Method
  uid: cntk.ops.functions.Function.grad
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.inputs
  summary: 'List of variables that are inputs of this function.

    Note that ''inputs'' here denotes all Variables that feed into this Function

    including any Parameter/Constant Variables that are children of this Function.'
  type: Property
  uid: cntk.ops.functions.Function.inputs
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.is_block
  summary: 'Returns a boolean indicating if this Function is a block function which
    is basically

    a composite encapsulated as an opaque block which appears as a primitive during

    traversing the graph of Functions that this block is part of.'
  type: Property
  uid: cntk.ops.functions.Function.is_block
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.is_composite
  summary: 'Returns a boolean indicating if this Function is a composite Function.

    A composite Function is a Function that is composed of primitive Functions.'
  type: Property
  uid: cntk.ops.functions.Function.is_composite
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.is_primitive
  summary: 'Returns a boolean indicating if this Function is a primitive Function.

    A primitive Function is the lowest level building block for composite Function

    graphs and is either a CNTK built-in operator, a composite Function encapsulated

    as a Block or a user-defined Function'
  type: Property
  uid: cntk.ops.functions.Function.is_primitive
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.load
  summary: "Load the ``model``, that has been saved using :func:`~cntk.ops.functions.Function.save`.\n\
    \n:param model: either a file path of a model file or a byte buffer\n        \
    \      containing the binary representation of a model.\n:type model: str, bytes\
    \ or bytearray\n:param device: specifies the device to allocate the model on.\n\
    :type device: :class:`~cntk.device.DeviceDescriptor`, defaults to the current\
    \ globally default device\n\n:returns: root node\n"
  type: Method
  uid: cntk.ops.functions.Function.load
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.name
  summary: "Name of this function\n\n:param getter: returns the name of the function.\n\
    :type getter: str\n:param setter: sets the name of the function. Setting the name\
    \ of a\n               Function is only allowed if the Function does not already\
    \ have a\n               name. Calling this method, when this Function already\
    \ has a name,\n               results in an exception.\n:type setter: str"
  type: Property
  uid: cntk.ops.functions.Function.name
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.op_name
  summary: Name of the operation that this Function performs
  type: Property
  uid: cntk.ops.functions.Function.op_name
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.output
  summary: The single output variable if there is only one, or raises an exception.
  type: Property
  uid: cntk.ops.functions.Function.output
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.outputs
  summary: List consisting of all output variables of this function.
  type: Property
  uid: cntk.ops.functions.Function.outputs
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.parameters
  summary: List of all parameter variables of this function.
  type: Property
  uid: cntk.ops.functions.Function.parameters
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.placeholders
  summary: List of all placeholders variables of this function.
  type: Property
  uid: cntk.ops.functions.Function.placeholders
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.register_udf_deserialize_callback
  summary: "Register a callback function to be invoked when deserializing a user-\n\
    defined function with the corresponding op name.\n\nWhen loading a model, CNTK\
    \ will try to automatically reconstruct any\n(non-native) user-defined functions\
    \ by invoking a static\n:func:`~cntk.ops.functions.UserFunction.deserialize` method\
    \ of the\ncorresponding UserFunction sub-class. This method allows to override\n\
    default UDF deserialization behavior by specifying a user- defined\nfunction op\
    \ name and the corresponding callback that should be invoked\ninstead of the ``deserialize``\
    \ method.\n\n:param op_name: unique op name of the user-defined function.\n:type\
    \ op_name: str\n:param callback: a function taking three arguments (a list of\n\
    \                 inputs to the UserFunction, a string name, and a state dictionary\n\
    \                 generated by the corresponding :func:`~cntk.ops.functions.UserFunction.serialize`\n\
    \                 method) and returns an instance of the user-defined function.\n\
    :type callback: function\n"
  type: Method
  uid: cntk.ops.functions.Function.register_udf_deserialize_callback
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.replace_placeholder
  summary: "In-place replace the only placeholder in the function graph with the\n\
    specified substitution.\n\n:param substitution: the variable\n               \
    \      that will replace the placeholder\n:type substitution: :class:`~cntk.variables.Variable`\n\
    \n:returns: itself\n:rtype: :class:`Function`\n\n:raises Exception: when the function\
    \ has multiple placeholders.\n"
  type: Method
  uid: cntk.ops.functions.Function.replace_placeholder
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.replace_placeholders
  summary: 'In-place replace specified placeholders in the Function graph with the

    specified replacements in the map.


    :param substitutions: map from placeholder to variables

    :type substitutions: dict


    :returns: itself

    :rtype: :class:`Function`

    '
  type: Method
  uid: cntk.ops.functions.Function.replace_placeholders
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.restore
  summary: 'Restore the models parameters (in-place) from a saved model file


    :param filename: saved model path

    :type filename: str


    :returns: this method only has the side-effect of loading the model parameters
    from the file

    :rtype: `None`

    '
  type: Method
  uid: cntk.ops.functions.Function.restore
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.root_function
  summary: The primitive function at the root of the graph of functions underlying
    this function.
  type: Property
  uid: cntk.ops.functions.Function.root_function
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.save
  summary: 'Save this function graph into a model file using protobuf-based

    serialization.


    Use distributed.Communicator.is_main() to gate your call to save()

    in distributed environment.


    :param filename: model path

    :type filename: str

    '
  type: Method
  uid: cntk.ops.functions.Function.save
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.set_attribute
  summary: "Allows to change a function attribute.\n\n:param name: one of\n\n    \
    \         * 'dropoutRate': modifies the dropout rate of a dropout function\n \
    \              (can only be invoked on a function instance returned either from\n\
    \               :func:`~cntk.ops.dropout` or :func:`find_by_name`).\n\n      \
    \       * 'rngSeed': modifies the seed of a stateful function (can only be\n \
    \              invoked on  function instance returned from :func:`~cntk.ops.dropout`,\n\
    \               :func:`~cntk.ops.random_sample`,\n               :func:`~cntk.ops.random_sample_inclusion_frequency`\
    \ or :func:`find_by_name`)\n:type name: string\n:param value: the new value\n\
    \              of the corresponding attribute.\n:type value: float in case of\
    \ 'dropoutRate', int for 'rngSeed'\n"
  type: Method
  uid: cntk.ops.functions.Function.set_attribute
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.signature
  summary: 'Returns the signature of a Function.

    This is the .arguments[] list without placeholders that belong to an outer, not
    yet completed @Function def.'
  type: Property
  uid: cntk.ops.functions.Function.signature
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.test
  summary: "Measures the performance of a model, given by its criterion function,\
    \ in the form of\naverage metric value (or loss if model has only one output)\
    \ on a set of data.\n\nThis is a convenience wrapper around :class:`cntk.eval.evaluator.Evaluator`.\n\
    \n:param minibatch_source: minibatch source for the test data\n:type minibatch_source:\
    \ :class:`~cntk.io.MinibatchSource`\n:param minibatch_size: minibatch size for\
    \ evaluation\n:type minibatch_size: :class:`~cntk.cntk_py.minibatch_size_schedule`\
    \ or int\n:param streams: the streams of the minibatch_source in argument order\n\
    :type streams: tuple\n:param model_inputs_to_streams: mapping between input variables\
    \ and input streams\n:type model_inputs_to_streams: dict\n:param callbacks: optionally,\
    \ list of\n                  progress writers from :mod:`cntk.logging` to automatically\
    \ track training\n                  progress.\n:type callbacks: progress writer\
    \ or list of them\n\n:returns: An object `test_summary` with `test_summary.metric`\
    \ being the average metric, and `test_summary.samples` the number of labels in\
    \ the test set.\n"
  type: Method
  uid: cntk.ops.functions.Function.test
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.train
  summary: "Trains a model, given by its criterion function, using the specified training\
    \ parameters and configs.\nDifferent aspects of training such as data sources,\
    \ checkpointing, cross validation, progress printing\ncan be configured using\
    \ the corresponding config classes.\n\nThe input data can be specified as a data\
    \ reader (:class:`~cntk.io.MinibatchSource`)\nfor large corpora; or directly as\
    \ numpy/scipy arrays if the data is so small that it\nis feasible to keep it all\
    \ in RAM.\n\nData is processed in minibatches. The minibatch size defaults to\
    \ 32, which is a choice that commonly works well.\nHowever, for maximum efficiency,\
    \ we recommend to experiment with minibatch sizes\nand choose the largest that\
    \ converges well and does not exceed the GPU RAM.\nThis is particularly important\
    \ for distributed training, where\noften, the minibatch size can be increased\
    \ throughout the training, which reduces data bandwidth\nand thus speeds up parallel\
    \ training.\n\nIf input data is given through a data reader (as opposed to directly\
    \ as a numpy/scipy array),\nthe user must also specify the epoch size. This is\
    \ because data readers are used for\nlarge corpora, and the traditional definition\
    \ of epoch size as number of samples in the corpus\nis not very relevant. Instead,\
    \ CNTK really means the number of samples\nbetween summary actions, such as printing\
    \ training progress, adjusting the learning rate, and/or checkpointing the model.\n\
    \nThe function returns an object that contains these members: `epoch_summaries`\
    \ is a list that\ncontains the progression of epoch loss (`.loss`) and metric\
    \ (`.metric`) values and the corresponding\nnumber of labels (`.samples`) that\
    \ they were averaged over. This is the same value that a progress printer would\
    \ print as epoch\nsummaries. `updates` is a similar list with the more fine-grained\
    \ minibatch updates.\nIf a `TestConfig` was specified, then `test_summary` is\
    \ the metric and sample count on the specified test set\nfor the final model.\n\
    \nA number of callback mechanisms can optionally be specified as a list as `callbacks`.\n\
    CNTK has a fixed set of callback types, and only those types are allowed in the\
    \ `callbacks` list:\nAn object of type :class:`~cntk.cntk_py.ProgressWriter` from\
    \ :mod:`cntk.logging` is used for progress logging;\na :class:`~cntk.train.training_session.CheckpointConfig`\
    \ configures the checkpointing mechanism, which\nkeeps copies of models at regular\
    \ intervals and allows to seamlessly restart from a last checkpoint;\na :class:`~cntk.train.training_session.TestConfig`\
    \ allows to specify a test set that is evaluated at the end of the training;\n\
    and a :class:`~cntk.train.training_session.CrossValidationConfig` specifies a\
    \ user callback that can be used to adjust learning\nhyper-parameters or to denote\
    \ to stop training, optionally based on a separate cross-validation data set.\n\
    \nThis is a convenience wrapper around :class:`cntk.train.trainer.Trainer` :class:`cntk.train.training_session.TrainingSession`.\n\
    \n:param self: the criterion function of a model to be trained. This is either\
    \ a single-valued function (the loss)\n             or a tuple-valued function\
    \ (loss and metric).\n:param minibatch_source: data source used for training.\
    \ For large data, use a MinibatchSource. For small data, pass a tuple of numpy/scipy\
    \ arrays.\n                         The number of streams/arrays must match the\
    \ number of arguments of `self`.\n:type minibatch_source: :class:`~cntk.io.MinibatchSource`\
    \ or tuple of numpy/scripy arrays\n:param streams: (only if minibatch_source is\
    \ a data reader) the streams of the minibatch_source in argument order.\n    \
    \            Not to be given if minibatch_source is specified as numpy/scipy arrays\
    \ rather than a data reader.\n:type streams: tuple\n:param minibatch_size: minibatch\
    \ size (or schedule) for training\n:type minibatch_size: int or :class:`~cntk.cntk_py.minibatch_size_schedule`,\
    \ defaults to 32\n:param epoch_size: in CNTK, epoch size means the number of samples\
    \ between outputting summary information and/or checkpointing.\n             \
    \      This must be specified unless the user directly passes numpy/scipy arrays\
    \ for the `minibatch_source`.\n:type epoch_size: int\n:param max_epochs: maximum\
    \ number of samples used for training; requires `epoch_size`\n:type max_epochs:\
    \ int, defaults to 1\n:param parameter_learners: list of learners from :mod:`cntk.learners`\n\
    :type parameter_learners: list\n:param callbacks: list of callback objects, which\
    \ can be of type\n                  :class:`~cntk.cntk_py.ProgressWriter` from\
    \ :mod:`cntk.logging` (for logging),\n                  :class:`~cntk.train.training_session.CheckpointConfig`\
    \ (for check-pointing),\n                  :class:`~cntk.train.training_session.TestConfig`\
    \ (for automatic final evaluation on a test set), and\n                  :class:`~cntk.train.training_session.CrossValidationConfig`\
    \ (for cross-validation based training control).\n                  Except for\
    \ progress writers, at most one of each is allowed.\n:type callbacks: list\n:param\
    \ model_inputs_to_streams: alternative to `streams`, specifying the mapping as\
    \ a map from input variables to streams\n:type model_inputs_to_streams: dict\n\
    :param max_samples: maximum number of samples used for training; mutually exclusive\
    \ with `max_epochs`\n:type max_samples: int\n:param progress_frequency: frequency\
    \ in samples for aggregated progress printing. Defaults to `epoch_size` if given,\
    \ or `None` otherwise\n:type progress_frequency: int\n\n.. admonition:: Example\n\
    \n   >>> # a simple logistic-regression model\n   >>> N = 250\n   >>> np.random.seed(0)\n\
    \   >>> Y = np.random.randint(size=N, low=0, high=2)  # labels\n   >>> X = (np.random.randn(N,\
    \ 2)+3) * (Y[:,None]+1)   # data\n   >>> # Our model expects float32 features,\
    \ and cross-entropy expects one-hot encoded labels.\n   >>> import scipy.sparse\n\
    \   >>> Y = scipy.sparse.csr_matrix((np.ones(N,np.float32), (range(N), Y)), shape=(N,\
    \ 2))\n   >>> X = X.astype(np.float32)\n   >>> model = cntk.layers.Dense(2, activation=None)\
    \ # model function\n   >>> import cntk.layers\n   >>> @cntk.Function.with_signature(cntk.layers.Tensor[2],\
    \ cntk.layers.SparseTensor[2]) # criterion function\n   ... def criterion(data,\
    \ label_one_hot):\n   ...     z = model(data)  # apply model. Computes a non-normalized\
    \ log probability for every output class.\n   ...     return cntk.cross_entropy_with_softmax(z,\
    \ label_one_hot)\n   >>> learner = cntk.sgd(model.parameters, cntk.learning_rate_schedule(0.1,\
    \ cntk.UnitType.minibatch))\n   >>> progress = criterion.train((X, Y), minibatch_size=25,\
    \ max_epochs=2, epoch_size=125, parameter_learners=[learner])\n   >>> print(\"\
    %.2f\" % progress.epoch_summaries[-1].loss) # get the final epoch's loss value\n\
    \   0.76\n\n:returns:\n\n          An object `progress` with `progress.epoch_summaries`\
    \ and `progress.updates` being the progressions of av loss, av metric, and number\
    \ of labels\n           for epochs and updates (groups of minibatches), respectively.\
    \ If a `TestConfig` was given, then `progress.test_summary`\n           includes\
    \ the result (.metric and .samples)\n"
  type: Method
  uid: cntk.ops.functions.Function.train
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.type
  summary: Get type of a Function's output.
  type: Property
  uid: cntk.ops.functions.Function.type
- _type: attribute
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.uid
  summary: The internally generated unique name of the function.
  type: Property
  uid: cntk.ops.functions.Function.uid
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.update_signature
  summary: 'Defines input shapes, in-place

    e.g.

    model.update_signature(42)

    pass a list of objects that define the dimensions etc. of the placeholders

    Currently you can pass an int, a tuple, an Input, or a dict created with Type()

    '
  type: Method
  uid: cntk.ops.functions.Function.update_signature
- _type: method
  class: cntk.ops.functions.Function
  module: cntk.ops.functions
  name: cntk.ops.functions.Function.with_signature
  summary: "Decorator for defining a @Function with a given signature. Same as @Function\
    \ followed by @Signature.\n\n.. admonition:: Example\n\n   >>> from cntk.layers.typing\
    \ import *\n   >>> @Function.with_signature(Tensor[13])\n   ... def f(x):\n  \
    \ ...     return x * x\n   >>> print(f)\n   ElementTimes(x: Tensor[13]) -> Tensor[13]\n\
    \   >>> # which is equivalent to this:\n   >>> @Function\n   ... @Signature(Tensor[13])\n\
    \   ... def f(x):\n   ...     return x * x\n   >>> print(f)\n   ElementTimes(x:\
    \ Tensor[13]) -> Tensor[13]\n"
  type: Method
  uid: cntk.ops.functions.Function.with_signature
- _type: class
  children:
  - cntk.ops.functions.UserFunction.clone
  - cntk.ops.functions.UserFunction.deserialize
  - cntk.ops.functions.UserFunction.infer_outputs
  - cntk.ops.functions.UserFunction.op_name
  - cntk.ops.functions.UserFunction.serialize
  module: cntk.ops.functions
  name: cntk.ops.functions.UserFunction
  summary: "Base class of all user extension functions.\n\nIf it has only one output,\
    \ one can invoke Variable methods on it, which it\nwill relay to its only output.\n\
    \n:param inputs: inputs to this function\n:type inputs: list\n:param as_numpy:\
    \ whether the data should be automatically\n                 converted from and\
    \ to NumPy. Defaults to True. Specifying this as\n                 `False` passes\
    \ the data as CNTK Value objects.\n:type as_numpy: bool, optional\n:param name:\
    \ name of this function\n:type name: str\n"
  type: Class
  uid: cntk.ops.functions.UserFunction
- _type: method
  class: cntk.ops.functions.UserFunction
  module: cntk.ops.functions
  name: cntk.ops.functions.UserFunction.clone
  summary: "Creates a clone of this user-defined function.\n\nIt assumes that the\
    \ constructor signature of the user's implementation\nof the user function takes\
    \ the inputs as individual arguments followed\nby the operator name. If the signature\
    \ is different, then this method\nneeds to be overriden.\n\n:param cloned_inputs:\
    \ list of cloned inputs to the new user-defined\n                      Function\
    \ clone to be created.\n\n:returns: A cloned instance of this user-defined function.\n"
  type: Method
  uid: cntk.ops.functions.UserFunction.clone
- _type: method
  class: cntk.ops.functions.UserFunction
  module: cntk.ops.functions
  name: cntk.ops.functions.UserFunction.deserialize
  summary: "A stub deserialize method for illustration purposes. User-defined functions\n\
    need to provide their own implementation in order for CNTK to be able to\nreconstruct\
    \ them when loading a model.\n\n:param inputs: a list of inputs to the function\n\
    :type inputs: list\n:param name: name of this function\n:type name: str\n:param\
    \ state: a state dictionary generated by the corresponding\n              :func:`~cntk.ops.functions.UserFunction.serialize`\
    \ method.\n:type state: dict\n\n:returns: An instance of the user-defined function.\n"
  type: Method
  uid: cntk.ops.functions.UserFunction.deserialize
- _type: method
  class: cntk.ops.functions.UserFunction
  module: cntk.ops.functions
  name: cntk.ops.functions.UserFunction.infer_outputs
  summary: 'Returns a list of all output variables this user-defined function

    outputs.


    Output variables are created by

    :meth:`~cntk.ops.output_variable`.

    '
  type: Method
  uid: cntk.ops.functions.UserFunction.infer_outputs
- _type: attribute
  class: cntk.ops.functions.UserFunction
  module: cntk.ops.functions
  name: cntk.ops.functions.UserFunction.op_name
  summary: 'Unique operation name of this user-defined function.

    This property defaults to ''<module>.<class>'', but can be overridden.'
  type: Property
  uid: cntk.ops.functions.UserFunction.op_name
- _type: method
  class: cntk.ops.functions.UserFunction
  module: cntk.ops.functions
  name: cntk.ops.functions.UserFunction.serialize
  summary: 'Generates a dictionary that captures the state of this user-defined function.


    This method must be overridden, if a user function has any state that needs

    to be preserved in the model dictionary.

    '
  type: Method
  uid: cntk.ops.functions.UserFunction.serialize
- _type: function
  module: cntk.ops.functions
  name: cntk.ops.functions.load_model
  summary: 'Alias for :func:`~cntk.ops.functions.Function.load`.

    '
  type: Method
  uid: cntk.ops.functions.load_model
- _type: function
  module: cntk.ops.functions
  name: cntk.ops.functions.native_user_function
  summary: "Creates an instance of a user-defined Function previously registered using\
    \ the\n'register_native_user_function' method.\n\n:param op_id: Id of the native\
    \ user-defined Function to instantiate.\n              This must be the id that\
    \ was used when registering the native user-function\n              with the 'register_native_user_function'\
    \ method.\n:type op_id: str\n:param operands: input operands of the new instance\
    \ of the native user-defined Function.\n:type operands: list\n:param user_function_instance_name:\
    \ Name of the instance of the created native\n                               \
    \     user-defined Function.\n:type user_function_instance_name: str\n\n:returns:\
    \ :class:`~cntk.ops.functions.Function`\n"
  type: Method
  uid: cntk.ops.functions.native_user_function
- _type: function
  module: cntk.ops.functions
  name: cntk.ops.functions.register_native_user_function
  summary: "Registers a native user-defined Function that can be subsequently instantiated\n\
    using the 'native_user_function' method.\n\n:param op_id: Unique id of the native\
    \ user-defined Function to register.\n              This id must be unique and\
    \ an error will be reported if it matches\n              the 'op_id' specified\
    \ for any other registered native user-defined Function.\n:type op_id: str\n:param\
    \ module_name: Name of the module containing the factory method for creating\n\
    \                    instances of the native user-defined Function being registered.\
    \ This is typically\n                    the name of a DLL/so which exports a\
    \ factory method for creating instances of the\n                    native user-defined\
    \ Function.\n:type module_name: str\n:param factory_method_name: Name of the factory\
    \ method for creating instances of the native\n                            user-defined\
    \ Function being registered. This method must be an exported method of the\n \
    \                           specified module.\n:type factory_method_name: str\n"
  type: Method
  uid: cntk.ops.functions.register_native_user_function
